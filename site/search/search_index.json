{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to Anomeda anomeda package helps you analyze non-aggregated time-series data with Python and quickly indentify important changes of your metric . Here is a brief example of how anomeda can work for you. \"Why has the number of our website visits decreased a week ago? What kind of users caused that?\" - anomeda will answer such questions quickly by processing non-aggregated visits of your website. It will show you, for instance, that users from the X country using the Y device suddenly stopped visiting your website. Not only that, even if you are not aware of any significant change of the number of visits, anomeda will highlight the cluster of events where it happened. Is it fraudulent activity, a paused marketing campaign or technical issues? It's up to you to investigate. The package is easy-to-use and adjustable enough to meet a wide range of real scenarios. The basic object, anomeda.DataFrame , inherits pandas.DataFrame , so you will find the API familiar. In addition, there are different options for fine-tuning alghorithms used under the hood. Some of what anomeda can do for your non-aggregated data : Highlight time points and clusters when the trend, mean or variance changed Fit trends for any cluster considering the points where trends change Highlight time points and clusters if the anomalies were observed, considering trend at that moment Compare time periods and find clusters changing the metric Find the project in its GitHub repo . Explore the Documentation of anomeda . Quick start Let's imagine you oversee the number of visits of a website. You have a table with visits. Typically you just aggregate them by a datetime column and monitor from 3 to 5 dashboards with overall number of visits, as well as visits of important pages, visits from specific systems, visits of specific users clustes, etc. Here is what you would do with anomeda . Let's define an anomeda object. import anomeda anomeda_df = anomeda.DataFrame( df, # pandas.DataFrame measures_names=['country', 'system', 'url', 'duration'], # columns represending measures or characteristics of your events measures_types={ 'categorical': [;'country', 'system', 'url'], 'continuous': ['duration'] # measures can also be continuous - anomeda will take care of clustering them properly }, index_name='date', metric_name='visit', # dummy metric, always 1 agg_func='sum' # function that is used to aggregate metric ) anomeda.DataFrame inherits pandas.DataFrame , so you can treat them similarly. NOTE Some pandas methods are not yet adapted for anomeda . They return a new pandas.DataFrame instead of a anomeda.DataFrame . You just need to initialize an anomeda object with a returned object in that case. Let's try to extract trends for important clusters from the data. trends = anomeda.fit_trends( anomeda_df, trend_fitting_conf={'max_trends': 'auto', 'min_var_reduction': 0.75}, # set the number of trends automatically, # try to reduce error variance compared to error of estimating values by 1-line trend by 75% breakdown='all-clusters', # fit trends for clusters extracted from all possible sets of measures mettic_propagte='zeros', # if some index values are missed after aggregation for a cluster, fill them with zeros min_cluster_size=3 # skip small clusters, they all will be combined into 'skipped' cluster ) Typically you will see something like this: You can then plot the trends using the plot_trends method. You can choose a specific cluster or plot them all together. anomeda.plot_trends(anomeda_df, clusters=['`country`==\"Germany\"']) The output will look like this: Of course, you may have no idea which cluster caused the problem and what to plot. Almost always you know only that there is a decrease of an overall metric and you need to find the culprits. Let's utilize another method -- anomeda.compare_clusters . anomeda.compare_clusters( anomeda_df, period1='date < \"2024-01-30\"', period2='date >= \"2024-01-30\"' ) You see the clusters you fitted before and comparison between their characteristics. The result is quite hefty, but you can easily add your own metrics and sort clusters so that the cluster you are looking for will be on top. For example, look at how different means in the second cluster are. The second cluster corresponds to Germany (the first cluster consists of all events, so we are not interested in it now). Finally, you can check if there are any point anomalies present in any of your clusters. anomeda.find_anomalies( anomeda_df, anomalies_conf: {'p_large': 1, 'p_low': 1, 'n_neighbors': 3} ) The output will look like this: If you plot the metric with its clusters, it would look quite reasonable. There are some nuances of how to use anomeda wisely and powerfully. For example, you may use same anomeda methods simply with numpy arrays, without creating DataFrame's! See full Documentation for more details and hints. Installing anomeda is availale from PyPI. You may run a pip install command: pip install anomeda Also, the GitHub repo contains the source and built distribution files in dist folder. You must have such packages be installed: pandas numpy sklearn scipy matplotlib Contribution You are very welcome to participate in developing to the project. You may solve the current issues or add new functionality - it is up for you to decide. Here is how your flow may look like: Preparing your Fork Click \u2018Fork\u2019 on Github, creating e.g. yourname/theproject. Clone your project: git clone git@github.com:yourname/theproject. cd theproject Create and activate a virtual environment. Install the development requirements: pip install -r dev-requirements.txt. Create a branch: git checkout -b my_branch Making your Changes Make the changes Write tests checking your code works for different scenarious Run tests, make sure they pass. Commit your changes: git commit -m \"Foo the bars\" Creating Pull Requests Push your commit to get it back up to your fork: git push origin HEAD Visit Github, click handy \u201cPull request\u201d button that it will make upon noticing your new branch. In the description field, write down issue number (if submitting code fixing an existing issue) or describe the issue + your fix (if submitting a wholly new bugfix). Hit \u2018submit\u2019! Reporting issues To report an issue, you should use Issues section of the project's page on Github. We will try to solve the issue as soon as possible. Contacts If you have any questions related to anomeda project, feel free reaching out to the author.","title":"Overview"},{"location":"#introduction-to-anomeda","text":"anomeda package helps you analyze non-aggregated time-series data with Python and quickly indentify important changes of your metric . Here is a brief example of how anomeda can work for you. \"Why has the number of our website visits decreased a week ago? What kind of users caused that?\" - anomeda will answer such questions quickly by processing non-aggregated visits of your website. It will show you, for instance, that users from the X country using the Y device suddenly stopped visiting your website. Not only that, even if you are not aware of any significant change of the number of visits, anomeda will highlight the cluster of events where it happened. Is it fraudulent activity, a paused marketing campaign or technical issues? It's up to you to investigate. The package is easy-to-use and adjustable enough to meet a wide range of real scenarios. The basic object, anomeda.DataFrame , inherits pandas.DataFrame , so you will find the API familiar. In addition, there are different options for fine-tuning alghorithms used under the hood. Some of what anomeda can do for your non-aggregated data : Highlight time points and clusters when the trend, mean or variance changed Fit trends for any cluster considering the points where trends change Highlight time points and clusters if the anomalies were observed, considering trend at that moment Compare time periods and find clusters changing the metric Find the project in its GitHub repo . Explore the Documentation of anomeda .","title":"Introduction to Anomeda"},{"location":"#quick-start","text":"Let's imagine you oversee the number of visits of a website. You have a table with visits. Typically you just aggregate them by a datetime column and monitor from 3 to 5 dashboards with overall number of visits, as well as visits of important pages, visits from specific systems, visits of specific users clustes, etc. Here is what you would do with anomeda . Let's define an anomeda object. import anomeda anomeda_df = anomeda.DataFrame( df, # pandas.DataFrame measures_names=['country', 'system', 'url', 'duration'], # columns represending measures or characteristics of your events measures_types={ 'categorical': [;'country', 'system', 'url'], 'continuous': ['duration'] # measures can also be continuous - anomeda will take care of clustering them properly }, index_name='date', metric_name='visit', # dummy metric, always 1 agg_func='sum' # function that is used to aggregate metric ) anomeda.DataFrame inherits pandas.DataFrame , so you can treat them similarly. NOTE Some pandas methods are not yet adapted for anomeda . They return a new pandas.DataFrame instead of a anomeda.DataFrame . You just need to initialize an anomeda object with a returned object in that case. Let's try to extract trends for important clusters from the data. trends = anomeda.fit_trends( anomeda_df, trend_fitting_conf={'max_trends': 'auto', 'min_var_reduction': 0.75}, # set the number of trends automatically, # try to reduce error variance compared to error of estimating values by 1-line trend by 75% breakdown='all-clusters', # fit trends for clusters extracted from all possible sets of measures mettic_propagte='zeros', # if some index values are missed after aggregation for a cluster, fill them with zeros min_cluster_size=3 # skip small clusters, they all will be combined into 'skipped' cluster ) Typically you will see something like this: You can then plot the trends using the plot_trends method. You can choose a specific cluster or plot them all together. anomeda.plot_trends(anomeda_df, clusters=['`country`==\"Germany\"']) The output will look like this: Of course, you may have no idea which cluster caused the problem and what to plot. Almost always you know only that there is a decrease of an overall metric and you need to find the culprits. Let's utilize another method -- anomeda.compare_clusters . anomeda.compare_clusters( anomeda_df, period1='date < \"2024-01-30\"', period2='date >= \"2024-01-30\"' ) You see the clusters you fitted before and comparison between their characteristics. The result is quite hefty, but you can easily add your own metrics and sort clusters so that the cluster you are looking for will be on top. For example, look at how different means in the second cluster are. The second cluster corresponds to Germany (the first cluster consists of all events, so we are not interested in it now). Finally, you can check if there are any point anomalies present in any of your clusters. anomeda.find_anomalies( anomeda_df, anomalies_conf: {'p_large': 1, 'p_low': 1, 'n_neighbors': 3} ) The output will look like this: If you plot the metric with its clusters, it would look quite reasonable. There are some nuances of how to use anomeda wisely and powerfully. For example, you may use same anomeda methods simply with numpy arrays, without creating DataFrame's! See full Documentation for more details and hints.","title":"Quick start"},{"location":"#installing","text":"anomeda is availale from PyPI. You may run a pip install command: pip install anomeda Also, the GitHub repo contains the source and built distribution files in dist folder. You must have such packages be installed: pandas numpy sklearn scipy matplotlib","title":"Installing"},{"location":"#contribution","text":"You are very welcome to participate in developing to the project. You may solve the current issues or add new functionality - it is up for you to decide. Here is how your flow may look like: Preparing your Fork Click \u2018Fork\u2019 on Github, creating e.g. yourname/theproject. Clone your project: git clone git@github.com:yourname/theproject. cd theproject Create and activate a virtual environment. Install the development requirements: pip install -r dev-requirements.txt. Create a branch: git checkout -b my_branch Making your Changes Make the changes Write tests checking your code works for different scenarious Run tests, make sure they pass. Commit your changes: git commit -m \"Foo the bars\" Creating Pull Requests Push your commit to get it back up to your fork: git push origin HEAD Visit Github, click handy \u201cPull request\u201d button that it will make upon noticing your new branch. In the description field, write down issue number (if submitting code fixing an existing issue) or describe the issue + your fix (if submitting a wholly new bugfix). Hit \u2018submit\u2019!","title":"Contribution"},{"location":"#reporting-issues","text":"To report an issue, you should use Issues section of the project's page on Github. We will try to solve the issue as soon as possible.","title":"Reporting issues"},{"location":"#contacts","text":"If you have any questions related to anomeda project, feel free reaching out to the author.","title":"Contacts"},{"location":"anomeda_api/","text":"Anomeda methods API Here you can find the documentation for available endpoints of anomeda Python package. ::: utils options: heading_level: 2 show_root_toc_entry: false show_docstring_classes: false merge_init_into_class: false show_root_heading: false show_root_full_path: false separate_signature: true show_root_members_full_path: false","title":"Anomeda methods"},{"location":"anomeda_api/#anomeda-methods-api","text":"Here you can find the documentation for available endpoints of anomeda Python package. ::: utils options: heading_level: 2 show_root_toc_entry: false show_docstring_classes: false merge_init_into_class: false show_root_heading: false show_root_full_path: false separate_signature: true show_root_members_full_path: false","title":"Anomeda methods API"},{"location":"api_reference/","text":"Anomeda API Here you can find the documentation for all available endpoints of anomeda Python package. DataFrame DataFrame ( * args , ** kwargs ) Bases: DataFrame Data to be processed by anomeda. The class inherits pandas.DataFrame. Please note that whenever the underlying pandas.DataFrame object is changed, you may need to apply the constructor again in order to keep some of the characteristics of the data consistent with the new object. Parameters: *args \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. **kwargs \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. measures_names ( 'list | tuple' = None ) \u2013 A list containing columns considered as measures. If None, your data is supposed to have no measures. measures_types ( 'dict' = None ) \u2013 A dictionary containing 'categorical' and/or 'continuous' keys and list of measures as values. Continuous measures will be discretized automatically if not presented in discretized_measures parameter. If your data has any measures, you must provide its' types. discretized_measures_mapping ( 'dict' = None ) \u2013 Custom dictionary with a mapping between a discrete value of the meauser and corresponding continous ranges. The lower bound must be including, the higher bound must be excluding. It uses the following format: { 'measure_name': { discrete_value_1: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [...]], descrete_value_2: ... } } discretized_measures ( 'dict' = None ) \u2013 A dictionary containig names of the measures as keys and array-like objects containing customly discretized values of the measure. If not provided, continuous measures will be discretized automatically. index_name ( 'str | list | None' = None ) \u2013 An index column containg Integer or pandas.DatetimeIndex. If None, index is taken from the pandas.DataFrame. metric_name ( str ) \u2013 A metric column. agg_func \u2013 Way of aggregating metric_name by measures. Can be 'sum', 'avg', 'count' or callable compatible with pandas.DataFrame.groupby. Examples: anmd_df = anomeda.DataFrame( df, measures_names=['dummy_measure_col', 'dummy_numeric_measure_col'], measures_types={ 'categorical': ['dummy_measure_col'], 'continuous': ['dummy_numeric_measure_col'] }, index_name='dt', metric_name='metric_col', agg_func='sum' ) copy_anomeda_df copy_anomeda_df () Return a copy of an anomeda.DataFrame object get_agg_func get_agg_func () Return the function used to aggregate the metric by measures. get_discretization_mapping get_discretization_mapping () Return a dict with a mapping between discrete values and actual ranges of continous measures. In some cases, there may be more than one interval for each discrete values Examples: >>> anmd_df.get_discretization_mapping() { 'dummy_numeric_measure': { 0: [[0.08506988648110014, 0.982366623262143]], # [[inc, exl)] 1: [[0.9855150328648835, 2.458970726947438]] # [[inc, exl)] } } get_discretized_measures get_discretized_measures () Return discretized versions of continous measures. get_index_name get_index_name () Return the name of an index column. get_measures_names get_measures_names () Return a list of columns considered as measures. get_measures_types get_measures_types () Return the measures_types dict. get_metric_name get_metric_name () Return the name of a metric column. replace_df replace_df ( data : pandas . DataFrame , inplace = False , keep_clusters : bool = False , keep_trends : bool = False , keep_discretization : bool = False , ) Replace the pandas.DataFrame content, underlying the anomeda.DataFrame, with a new one Parameters: data ( DataFrame ) \u2013 A new data object. inplace ( bool , default: False ) \u2013 If True, then no new object will be returned. Otherwise, create and return a new anomeda.DataFrame set_agg_func set_agg_func ( agg_func ) Set a function to aggregate the metric by measures. Parameters: agg_func \u2013 Can be \"sum\", \"avg\", \"count\" or callable compatible with pandas.DataFrame.groupby set_discretization_mapping set_discretization_mapping ( discretized_measures_mapping , recalculate_measures = True ) Set custom thresholds for discretization. Parameters: discretized_measures_mapping ( dict ) \u2013 Dict with mapping between discrete value of the meause and corresponding continous values. Threshold must have the following format. As you can see, several different ranges of continuous values may be mapped into the same descrete values if you want. The lower bound must be including, the higher bound must be excluding. { 'measure_name': { discrete_value: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [..., ...], ...], ... }, ... } Examples: anmd_df.set_discretization_mapping({ 'dummy_numeric_measure': { 0: [[0.00, 0.05001], [0.95, 1.001]], # may correspond to \"extreme\" values; 0.05 are 1. are excluding bounds 1: [[0.5, 0.94999]] # may correspond to \"normal\" values; 94999 is an excluding bound } }) set_discretized_measures set_discretized_measures ( discretized_measures : dict ) Set custom discretization for continous measures. Parameters: discretized_measures ( dict ) \u2013 Dict containing discrete values of each measure in the format {'measure_name': [0, 1, 1, ...]}. Array of values must have same shape as original measure had. set_measures_names set_measures_names ( measures_names ) Let anomeda.DataFrame object know what columns are measures. Columns are picked from an underlying pandas.DataFrame object, so they must be present there. Parameters: measures_names ( list of str ) \u2013 List containing columns which will be considered as measures set_measures_types set_measures_types ( measures_types : dict ) Set measures types. Measure can be either 'categorical' or 'continous'. Types are used to clusterize the data properly. Parameters: measures_types ( dict ) \u2013 Dict containing 'continous' and/or 'categorical' keys and lists of measures as values Examples: anmd_df.set_measures_types({ 'continous': ['numeric_measure_1'], 'categorical': ['measure_1'] }) set_metric_name set_metric_name ( metric_name ) Set the name of a metric to be analyzed. Parameters: metric_name ( str ) \u2013 Must be present among columns of an underlying pandas.DataFrame. If metric column is currently set as a measure, you need to change the list of measures first compare_clusters compare_clusters ( data : anomeda . DataFrame , period1 : str , period2 : str , breakdown : \"no\" | \"all-clusters\" | list [ str ] = \"no\" , clusters : list = None , ) Compare metric values for 2 periods. The method generates pandas.DataFrame object with descriptions for two periods, for each cluster. You can use it to identify the cluster or set of clusters caused the differences in the overall metric values between two periods. Parameters: data ( DataFrame ) \u2013 Object containing data to be analyzed period1 ( str ) \u2013 Query to filter the first period. For example, 'dt < 10'. period2 ( str ) \u2013 Query to filter the second period. For example, 'dt >= 10'. breakdown ( no | all - clusters | list [ str ] , default: 'no' ) \u2013 If 'no', the metric is grouped by date points only. If 'all-clusters', then all combinations of measures are used to create clusters for fitting trends within them. If list[str], then only combinations of measures specified in the list are used. clusters ( list , default: None ) \u2013 List of clusters to use in the comparison. The objects in the list are queries used in pandas.DataFrame.query. If None, all clusters are used. Default is None. Returns: output ( DataFrame ) \u2013 Object describing the clusters and the changes in the metric behavior between them. Examples: anomeda.compare_clusters( data, period1='dt < 10', period2='dt >= 10', clusters=None # means all clusters ) extract_trends extract_trends ( x : numpy . ndarray [ int ] | pandas . DatetimeIndex , y : numpy . ndarray [ float ], freq : \"frequency unit for pandas.DatetimeIndex\" = None , propagation_strategy : \"zeros\" | \"ffil\" | None = None , max_trends : int | \"auto\" = \"auto\" , min_var_reduction : float [ 0 , 1 ] | None = 0.5 , verbose : bool = False , ) Fit and return automatocally fitted linear trends for given X and Y. The method can extract more than 1 trend if the metric significantly changed its behavior. The sensibility of the method to identify trend changes are set by parameters \"max_trends\" and \"min_var_reduction\". Parameters: x ( ndarray [ int ] | DatetimeIndex ) \u2013 Indeces corresponding to time points. Must be an increasing array of integers. Some of the values may be omitted, e.g such x is OK: [0, 1, 5, 10]. y ( ndarray [ float ] ) \u2013 Metric values corresponding to time points. propagation_strategy ( '\"zeros\" | \"ffil\" | None' = None , default: None ) \u2013 How to propogate aggregated time-series for missing index values. - zeros: Let metric for missing index be equal 0. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 0 '2024-01-03': 2 - ffil: Let metric for missing index be equal the last observed value. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 1 '2024-01-03': 2 - None: Use only present metric and index values. max_trends ( int | auto , default: \"auto\" ) \u2013 Number of trends to extract. If int, the method extracts defined amount of trends or less. Less trends may be extracted if no more trends were found or if the min_var_reduction is reached. It would mean taht the variance is already explained by that amount of trends. If 'auto', the method defines the number of trends automatically using min_var_reduction parameter. Default is 'auto'. min_var_reduction ( float [0, 1] | None , default: 0.5 ) \u2013 % of the variance of approximation error that must be reduced by adding trends comparing to the variance of the initial approximation with one trend. Values closer to 1 will cause extracting more trends, since more trends reduce the variance better. Values closer to 0 will cause producing less trends. If max_trends is set and reached, the extraction finishes regardless the value of the variance. If None, then not used. Default is 0.5. verbose ( bool , default: False ) \u2013 If to produce more logs. Default False. Returns: trends ( dict ) \u2013 Dict contains the extracted trends in the format { trend_id: (xmin_inc, xmax_exc, (trend_slope, trend_intersept), (n_samples, metric_mean, mae, metric_sum)), ... } Examples: >>> x = np . array ([ 0 , 1 , 4 , 5 ]) >>> y = np . array ([ 11.2 , 10.4 , 3.4 , 3.1 ]) >>> anomeda . extract_trends ( x , y , max_trends = 2 ) { 0: (0, 4, (-0.7999999999999989, 11.2), (2, 10.8, 0.0, 21.6)), # trend 1, for date points from 0 (inc) to 4 (excl) # with slope -0.79 and intercept 11.2 # consisting of 2 samples, # metric mean over date points is 10.8, # mae for fitting trend over date points is 0.0 # sum for all metric values is 21.6 1: (4, 6, (-0.2999999999999998, 4.6), (2, 3.25, 0.0, 6.5)) } find_anomalies find_anomalies ( data : anomeda . DataFrame | ( numpy . ndarray [ int ], numpy . ndarray [ float ]), clusters : list = None , anomalies_conf : dict = { \"p_large\" : 1 , \"p_low\" : 1 , \"n_neighbors\" : 3 , }, return_all_points : bool = False , trend_fitting_conf : dict = None , ) Find metric anomalies by looking for the most extreme metric changes. The method finds differences between real metric and a fitted trends, find points with extreme differences and marks them as anomalies. You can find anomalies for automatically extracted clusters only if passing an anomeda.DataFrame. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) ) \u2013 Object containing metric values to be analyzed. Trends must be fitted for the object with anomeda.fit_trends() method if anomeda.DataFrame is passed. clusters ( list , default: None ) \u2013 List of clusters to plot. The objects in the list are queries used in pandas.DataFrame.query. Make sure you pass the cluster names exactly as they they appear in the fitted trends. anomalies_conf ( dict , default: {'p_large': 1., 'p_low': 1., 'n_neighbors': 3} ) \u2013 Dict containing 'p_large' and 'p_low' values. Both are float values between 0 and 1 corresponding to the % of the anomalies with largest and lowest metric values to be returned. For example, if you set 'p_low' to 0, no points with abnormally low metric values will be returned; if 0.5, then 50% of points with abnormally values will be returned, etc. If some of the keys is not present or None, 1 is assumed. 'n_neighbors' means number of neighbors parameter for sklearn.neighbors.LocalOutlierFactor class. The class is used to find points with abnormally large MAE. The more the parameter, typically, the less sensitive the model to anomalies. return_all_points ( bool , default: False ) \u2013 If False, only anomaly points are returned. If True, all points with anomalies marks are returned. Default False. trend_fitting_conf ( dict , default: None ) \u2013 Used only if data is not anomeda.DataFrame, but numpy arrays, to run anomeda.fit_trends method for them. Parameters are similar to those you would pass to the argument anomeda.fit_trends(..., trend_fitting_conf=...). Returns: res ( DataFrame ) \u2013 A DataFrame containing fields 'cluster', 'index', 'metric_value', 'fitted_trend_value', 'anomaly'. Examples: >>> anomeda . fit_trends ( data ) >>> anomeda . find_anomalies ( data ) fit_trends fit_trends ( data : anomeda . DataFrame | ( numpy . ndarray [ int ], numpy . ndarray [ float ]) | ( pandas . DatetimeIndex , numpy . ndarray [ float ]), trend_fitting_conf : dict = { \"max_trends\" : \"auto\" , \"min_var_reduction\" : 0.75 , }, save_trends : bool = True , breakdown : \"no\" | \"all-clusters\" | list [ str ] = \"no\" , metric_propagate : \"zeros\" | \"ffil\" | None = None , min_cluster_size : int | None = None , max_cluster_size : int | None = None , plot : bool = False , df : bool = True , verbose : bool = False , ) Fit trends for a time series. Fit trends using the data from an anomeda.DataFrame or an numpy.ndarray with metric values. You can fit trends for automatically extracted clusters only if passing an anomeda.DataFrame. If anomeda.DataFrame is passed and \"save_trends\" is True, it stores the trends into anomeda.DataFrame._trends attribute of the class every time the method is called. The method returns a pandas.DataFrame describing trends and/or plots the trends. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) | ( DatetimeIndex , ndarray [ float ]) ) \u2013 Object containing metric values. If numpy.ndarray, a tuple of arrays corresponding to x (data points) and y (metric values) respectively. trend_fitting_conf ( dict , default: {'max_trends': 'auto', 'min_var_reduction': 0.75} ) \u2013 Parameters for calling anomeda.extract_trends() function. It consists of 'max_trends' parameter, which is responsible for the maximum number of trends that you want to identify, and 'min_var_reduction' parameter, which describes what part of variance must be reduced by estimating trends. Values close to 1 will produce more trends since more trends reduce variance more signigicantly. Default is {'max_trends': 'auto', 'min_var_reduction': 0.75}. save_trends ( bool , default: True ) \u2013 If False, return pandas.DataFrame with trends description without assigning it to the anomeda.DataFrame._trends. breakdown ( no | all - clusters | list [ str ] , default: 'no' ) \u2013 If 'no', the metric is grouped by date points only. If 'all-clusters', then all combinations of measures are used to create clusters for fitting trends within them. If list[str], then only combinations of measures specified in the list are used. metric_propagate ( '\"zeros\" | \"ffil\" | None' = None , default: None ) \u2013 How to propogate aggregated time-series for missing index values. - zeros: Let metric for missing index be equal 0. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 0 '2024-01-03': 2 - ffil: Let metric for missing index be equal the last observed value. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 1 '2024-01-03': 2 - None: Use only present metric and index values. min_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is less than the value. max_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is more than the value. plot ( bool , default: False ) \u2013 Indicator if to plot fitted trends. anomeda.plot_trends is responsibe for plotting if the flag is True. df ( bool , default: True ) \u2013 Indicator if to return a pandas.DataFrame containing fitted trends. verbose ( bool , default: False ) \u2013 Indicator if to print additional output. Returns: resp ( DataFrame ) \u2013 An object containing information about trends Examples: >>> fitted_trends = anomeda . fit_trends ( data, trend_fitting_conf={'max_trends': 3}, metric_propagate='zeros', min_cluster_size=3, plot=True, df=True ) plot_trends plot_trends ( data : \"anomeda.DataFrame | pandas.DataFrame returned from anomeda.fit_trends()\" , clusters : list = None , colors : dict = None , show_points = True , ) Plot fitted trends. Plot trends either from anomeda.DataFrame instance or using a response from anomeda.fit_trends(). Parameters: data ( anomeda.DataFrame | pandas.DataFrame returned from anomeda.fit_trends() ) \u2013 Object containing trends to be plotted. clusters ( list , default: None ) \u2013 List of clusters to plot. The objects in the list are queries used in pandas.DataFrame.query. Make sure you pass the cluster names exactly as they they appear in the fitted trends. colors ( dict , default: None ) \u2013 Dictionary with a mapping between clusters and colors used in matplotlib. show_points ( bool , default: True ) \u2013 Indicator if to show data points on plots. Returns: None \u2013 Examples: >>> anomeda . fit_trends ( data ) >>> anomeda . plot_trends ( data )","title":"Anomeda API"},{"location":"api_reference/#anomeda-api","text":"Here you can find the documentation for all available endpoints of anomeda Python package.","title":"Anomeda API"},{"location":"api_reference/#DataFrame.DataFrame","text":"DataFrame ( * args , ** kwargs ) Bases: DataFrame Data to be processed by anomeda. The class inherits pandas.DataFrame. Please note that whenever the underlying pandas.DataFrame object is changed, you may need to apply the constructor again in order to keep some of the characteristics of the data consistent with the new object. Parameters: *args \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. **kwargs \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. measures_names ( 'list | tuple' = None ) \u2013 A list containing columns considered as measures. If None, your data is supposed to have no measures. measures_types ( 'dict' = None ) \u2013 A dictionary containing 'categorical' and/or 'continuous' keys and list of measures as values. Continuous measures will be discretized automatically if not presented in discretized_measures parameter. If your data has any measures, you must provide its' types. discretized_measures_mapping ( 'dict' = None ) \u2013 Custom dictionary with a mapping between a discrete value of the meauser and corresponding continous ranges. The lower bound must be including, the higher bound must be excluding. It uses the following format: { 'measure_name': { discrete_value_1: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [...]], descrete_value_2: ... } } discretized_measures ( 'dict' = None ) \u2013 A dictionary containig names of the measures as keys and array-like objects containing customly discretized values of the measure. If not provided, continuous measures will be discretized automatically. index_name ( 'str | list | None' = None ) \u2013 An index column containg Integer or pandas.DatetimeIndex. If None, index is taken from the pandas.DataFrame. metric_name ( str ) \u2013 A metric column. agg_func \u2013 Way of aggregating metric_name by measures. Can be 'sum', 'avg', 'count' or callable compatible with pandas.DataFrame.groupby. Examples: anmd_df = anomeda.DataFrame( df, measures_names=['dummy_measure_col', 'dummy_numeric_measure_col'], measures_types={ 'categorical': ['dummy_measure_col'], 'continuous': ['dummy_numeric_measure_col'] }, index_name='dt', metric_name='metric_col', agg_func='sum' )","title":"DataFrame"},{"location":"api_reference/#DataFrame.DataFrame.copy_anomeda_df","text":"copy_anomeda_df () Return a copy of an anomeda.DataFrame object","title":"copy_anomeda_df"},{"location":"api_reference/#DataFrame.DataFrame.get_agg_func","text":"get_agg_func () Return the function used to aggregate the metric by measures.","title":"get_agg_func"},{"location":"api_reference/#DataFrame.DataFrame.get_discretization_mapping","text":"get_discretization_mapping () Return a dict with a mapping between discrete values and actual ranges of continous measures. In some cases, there may be more than one interval for each discrete values Examples: >>> anmd_df.get_discretization_mapping() { 'dummy_numeric_measure': { 0: [[0.08506988648110014, 0.982366623262143]], # [[inc, exl)] 1: [[0.9855150328648835, 2.458970726947438]] # [[inc, exl)] } }","title":"get_discretization_mapping"},{"location":"api_reference/#DataFrame.DataFrame.get_discretized_measures","text":"get_discretized_measures () Return discretized versions of continous measures.","title":"get_discretized_measures"},{"location":"api_reference/#DataFrame.DataFrame.get_index_name","text":"get_index_name () Return the name of an index column.","title":"get_index_name"},{"location":"api_reference/#DataFrame.DataFrame.get_measures_names","text":"get_measures_names () Return a list of columns considered as measures.","title":"get_measures_names"},{"location":"api_reference/#DataFrame.DataFrame.get_measures_types","text":"get_measures_types () Return the measures_types dict.","title":"get_measures_types"},{"location":"api_reference/#DataFrame.DataFrame.get_metric_name","text":"get_metric_name () Return the name of a metric column.","title":"get_metric_name"},{"location":"api_reference/#DataFrame.DataFrame.replace_df","text":"replace_df ( data : pandas . DataFrame , inplace = False , keep_clusters : bool = False , keep_trends : bool = False , keep_discretization : bool = False , ) Replace the pandas.DataFrame content, underlying the anomeda.DataFrame, with a new one Parameters: data ( DataFrame ) \u2013 A new data object. inplace ( bool , default: False ) \u2013 If True, then no new object will be returned. Otherwise, create and return a new anomeda.DataFrame","title":"replace_df"},{"location":"api_reference/#DataFrame.DataFrame.set_agg_func","text":"set_agg_func ( agg_func ) Set a function to aggregate the metric by measures. Parameters: agg_func \u2013 Can be \"sum\", \"avg\", \"count\" or callable compatible with pandas.DataFrame.groupby","title":"set_agg_func"},{"location":"api_reference/#DataFrame.DataFrame.set_discretization_mapping","text":"set_discretization_mapping ( discretized_measures_mapping , recalculate_measures = True ) Set custom thresholds for discretization. Parameters: discretized_measures_mapping ( dict ) \u2013 Dict with mapping between discrete value of the meause and corresponding continous values. Threshold must have the following format. As you can see, several different ranges of continuous values may be mapped into the same descrete values if you want. The lower bound must be including, the higher bound must be excluding. { 'measure_name': { discrete_value: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [..., ...], ...], ... }, ... } Examples: anmd_df.set_discretization_mapping({ 'dummy_numeric_measure': { 0: [[0.00, 0.05001], [0.95, 1.001]], # may correspond to \"extreme\" values; 0.05 are 1. are excluding bounds 1: [[0.5, 0.94999]] # may correspond to \"normal\" values; 94999 is an excluding bound } })","title":"set_discretization_mapping"},{"location":"api_reference/#DataFrame.DataFrame.set_discretized_measures","text":"set_discretized_measures ( discretized_measures : dict ) Set custom discretization for continous measures. Parameters: discretized_measures ( dict ) \u2013 Dict containing discrete values of each measure in the format {'measure_name': [0, 1, 1, ...]}. Array of values must have same shape as original measure had.","title":"set_discretized_measures"},{"location":"api_reference/#DataFrame.DataFrame.set_measures_names","text":"set_measures_names ( measures_names ) Let anomeda.DataFrame object know what columns are measures. Columns are picked from an underlying pandas.DataFrame object, so they must be present there. Parameters: measures_names ( list of str ) \u2013 List containing columns which will be considered as measures","title":"set_measures_names"},{"location":"api_reference/#DataFrame.DataFrame.set_measures_types","text":"set_measures_types ( measures_types : dict ) Set measures types. Measure can be either 'categorical' or 'continous'. Types are used to clusterize the data properly. Parameters: measures_types ( dict ) \u2013 Dict containing 'continous' and/or 'categorical' keys and lists of measures as values Examples: anmd_df.set_measures_types({ 'continous': ['numeric_measure_1'], 'categorical': ['measure_1'] })","title":"set_measures_types"},{"location":"api_reference/#DataFrame.DataFrame.set_metric_name","text":"set_metric_name ( metric_name ) Set the name of a metric to be analyzed. Parameters: metric_name ( str ) \u2013 Must be present among columns of an underlying pandas.DataFrame. If metric column is currently set as a measure, you need to change the list of measures first","title":"set_metric_name"},{"location":"api_reference/#utils.compare_clusters","text":"compare_clusters ( data : anomeda . DataFrame , period1 : str , period2 : str , breakdown : \"no\" | \"all-clusters\" | list [ str ] = \"no\" , clusters : list = None , ) Compare metric values for 2 periods. The method generates pandas.DataFrame object with descriptions for two periods, for each cluster. You can use it to identify the cluster or set of clusters caused the differences in the overall metric values between two periods. Parameters: data ( DataFrame ) \u2013 Object containing data to be analyzed period1 ( str ) \u2013 Query to filter the first period. For example, 'dt < 10'. period2 ( str ) \u2013 Query to filter the second period. For example, 'dt >= 10'. breakdown ( no | all - clusters | list [ str ] , default: 'no' ) \u2013 If 'no', the metric is grouped by date points only. If 'all-clusters', then all combinations of measures are used to create clusters for fitting trends within them. If list[str], then only combinations of measures specified in the list are used. clusters ( list , default: None ) \u2013 List of clusters to use in the comparison. The objects in the list are queries used in pandas.DataFrame.query. If None, all clusters are used. Default is None. Returns: output ( DataFrame ) \u2013 Object describing the clusters and the changes in the metric behavior between them. Examples: anomeda.compare_clusters( data, period1='dt < 10', period2='dt >= 10', clusters=None # means all clusters )","title":"compare_clusters"},{"location":"api_reference/#utils.extract_trends","text":"extract_trends ( x : numpy . ndarray [ int ] | pandas . DatetimeIndex , y : numpy . ndarray [ float ], freq : \"frequency unit for pandas.DatetimeIndex\" = None , propagation_strategy : \"zeros\" | \"ffil\" | None = None , max_trends : int | \"auto\" = \"auto\" , min_var_reduction : float [ 0 , 1 ] | None = 0.5 , verbose : bool = False , ) Fit and return automatocally fitted linear trends for given X and Y. The method can extract more than 1 trend if the metric significantly changed its behavior. The sensibility of the method to identify trend changes are set by parameters \"max_trends\" and \"min_var_reduction\". Parameters: x ( ndarray [ int ] | DatetimeIndex ) \u2013 Indeces corresponding to time points. Must be an increasing array of integers. Some of the values may be omitted, e.g such x is OK: [0, 1, 5, 10]. y ( ndarray [ float ] ) \u2013 Metric values corresponding to time points. propagation_strategy ( '\"zeros\" | \"ffil\" | None' = None , default: None ) \u2013 How to propogate aggregated time-series for missing index values. - zeros: Let metric for missing index be equal 0. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 0 '2024-01-03': 2 - ffil: Let metric for missing index be equal the last observed value. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 1 '2024-01-03': 2 - None: Use only present metric and index values. max_trends ( int | auto , default: \"auto\" ) \u2013 Number of trends to extract. If int, the method extracts defined amount of trends or less. Less trends may be extracted if no more trends were found or if the min_var_reduction is reached. It would mean taht the variance is already explained by that amount of trends. If 'auto', the method defines the number of trends automatically using min_var_reduction parameter. Default is 'auto'. min_var_reduction ( float [0, 1] | None , default: 0.5 ) \u2013 % of the variance of approximation error that must be reduced by adding trends comparing to the variance of the initial approximation with one trend. Values closer to 1 will cause extracting more trends, since more trends reduce the variance better. Values closer to 0 will cause producing less trends. If max_trends is set and reached, the extraction finishes regardless the value of the variance. If None, then not used. Default is 0.5. verbose ( bool , default: False ) \u2013 If to produce more logs. Default False. Returns: trends ( dict ) \u2013 Dict contains the extracted trends in the format { trend_id: (xmin_inc, xmax_exc, (trend_slope, trend_intersept), (n_samples, metric_mean, mae, metric_sum)), ... } Examples: >>> x = np . array ([ 0 , 1 , 4 , 5 ]) >>> y = np . array ([ 11.2 , 10.4 , 3.4 , 3.1 ]) >>> anomeda . extract_trends ( x , y , max_trends = 2 ) { 0: (0, 4, (-0.7999999999999989, 11.2), (2, 10.8, 0.0, 21.6)), # trend 1, for date points from 0 (inc) to 4 (excl) # with slope -0.79 and intercept 11.2 # consisting of 2 samples, # metric mean over date points is 10.8, # mae for fitting trend over date points is 0.0 # sum for all metric values is 21.6 1: (4, 6, (-0.2999999999999998, 4.6), (2, 3.25, 0.0, 6.5)) }","title":"extract_trends"},{"location":"api_reference/#utils.find_anomalies","text":"find_anomalies ( data : anomeda . DataFrame | ( numpy . ndarray [ int ], numpy . ndarray [ float ]), clusters : list = None , anomalies_conf : dict = { \"p_large\" : 1 , \"p_low\" : 1 , \"n_neighbors\" : 3 , }, return_all_points : bool = False , trend_fitting_conf : dict = None , ) Find metric anomalies by looking for the most extreme metric changes. The method finds differences between real metric and a fitted trends, find points with extreme differences and marks them as anomalies. You can find anomalies for automatically extracted clusters only if passing an anomeda.DataFrame. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) ) \u2013 Object containing metric values to be analyzed. Trends must be fitted for the object with anomeda.fit_trends() method if anomeda.DataFrame is passed. clusters ( list , default: None ) \u2013 List of clusters to plot. The objects in the list are queries used in pandas.DataFrame.query. Make sure you pass the cluster names exactly as they they appear in the fitted trends. anomalies_conf ( dict , default: {'p_large': 1., 'p_low': 1., 'n_neighbors': 3} ) \u2013 Dict containing 'p_large' and 'p_low' values. Both are float values between 0 and 1 corresponding to the % of the anomalies with largest and lowest metric values to be returned. For example, if you set 'p_low' to 0, no points with abnormally low metric values will be returned; if 0.5, then 50% of points with abnormally values will be returned, etc. If some of the keys is not present or None, 1 is assumed. 'n_neighbors' means number of neighbors parameter for sklearn.neighbors.LocalOutlierFactor class. The class is used to find points with abnormally large MAE. The more the parameter, typically, the less sensitive the model to anomalies. return_all_points ( bool , default: False ) \u2013 If False, only anomaly points are returned. If True, all points with anomalies marks are returned. Default False. trend_fitting_conf ( dict , default: None ) \u2013 Used only if data is not anomeda.DataFrame, but numpy arrays, to run anomeda.fit_trends method for them. Parameters are similar to those you would pass to the argument anomeda.fit_trends(..., trend_fitting_conf=...). Returns: res ( DataFrame ) \u2013 A DataFrame containing fields 'cluster', 'index', 'metric_value', 'fitted_trend_value', 'anomaly'. Examples: >>> anomeda . fit_trends ( data ) >>> anomeda . find_anomalies ( data )","title":"find_anomalies"},{"location":"api_reference/#utils.fit_trends","text":"fit_trends ( data : anomeda . DataFrame | ( numpy . ndarray [ int ], numpy . ndarray [ float ]) | ( pandas . DatetimeIndex , numpy . ndarray [ float ]), trend_fitting_conf : dict = { \"max_trends\" : \"auto\" , \"min_var_reduction\" : 0.75 , }, save_trends : bool = True , breakdown : \"no\" | \"all-clusters\" | list [ str ] = \"no\" , metric_propagate : \"zeros\" | \"ffil\" | None = None , min_cluster_size : int | None = None , max_cluster_size : int | None = None , plot : bool = False , df : bool = True , verbose : bool = False , ) Fit trends for a time series. Fit trends using the data from an anomeda.DataFrame or an numpy.ndarray with metric values. You can fit trends for automatically extracted clusters only if passing an anomeda.DataFrame. If anomeda.DataFrame is passed and \"save_trends\" is True, it stores the trends into anomeda.DataFrame._trends attribute of the class every time the method is called. The method returns a pandas.DataFrame describing trends and/or plots the trends. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) | ( DatetimeIndex , ndarray [ float ]) ) \u2013 Object containing metric values. If numpy.ndarray, a tuple of arrays corresponding to x (data points) and y (metric values) respectively. trend_fitting_conf ( dict , default: {'max_trends': 'auto', 'min_var_reduction': 0.75} ) \u2013 Parameters for calling anomeda.extract_trends() function. It consists of 'max_trends' parameter, which is responsible for the maximum number of trends that you want to identify, and 'min_var_reduction' parameter, which describes what part of variance must be reduced by estimating trends. Values close to 1 will produce more trends since more trends reduce variance more signigicantly. Default is {'max_trends': 'auto', 'min_var_reduction': 0.75}. save_trends ( bool , default: True ) \u2013 If False, return pandas.DataFrame with trends description without assigning it to the anomeda.DataFrame._trends. breakdown ( no | all - clusters | list [ str ] , default: 'no' ) \u2013 If 'no', the metric is grouped by date points only. If 'all-clusters', then all combinations of measures are used to create clusters for fitting trends within them. If list[str], then only combinations of measures specified in the list are used. metric_propagate ( '\"zeros\" | \"ffil\" | None' = None , default: None ) \u2013 How to propogate aggregated time-series for missing index values. - zeros: Let metric for missing index be equal 0. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 0 '2024-01-03': 2 - ffil: Let metric for missing index be equal the last observed value. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 1 '2024-01-03': 2 - None: Use only present metric and index values. min_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is less than the value. max_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is more than the value. plot ( bool , default: False ) \u2013 Indicator if to plot fitted trends. anomeda.plot_trends is responsibe for plotting if the flag is True. df ( bool , default: True ) \u2013 Indicator if to return a pandas.DataFrame containing fitted trends. verbose ( bool , default: False ) \u2013 Indicator if to print additional output. Returns: resp ( DataFrame ) \u2013 An object containing information about trends Examples: >>> fitted_trends = anomeda . fit_trends ( data, trend_fitting_conf={'max_trends': 3}, metric_propagate='zeros', min_cluster_size=3, plot=True, df=True )","title":"fit_trends"},{"location":"api_reference/#utils.plot_trends","text":"plot_trends ( data : \"anomeda.DataFrame | pandas.DataFrame returned from anomeda.fit_trends()\" , clusters : list = None , colors : dict = None , show_points = True , ) Plot fitted trends. Plot trends either from anomeda.DataFrame instance or using a response from anomeda.fit_trends(). Parameters: data ( anomeda.DataFrame | pandas.DataFrame returned from anomeda.fit_trends() ) \u2013 Object containing trends to be plotted. clusters ( list , default: None ) \u2013 List of clusters to plot. The objects in the list are queries used in pandas.DataFrame.query. Make sure you pass the cluster names exactly as they they appear in the fitted trends. colors ( dict , default: None ) \u2013 Dictionary with a mapping between clusters and colors used in matplotlib. show_points ( bool , default: True ) \u2013 Indicator if to show data points on plots. Returns: None \u2013 Examples: >>> anomeda . fit_trends ( data ) >>> anomeda . plot_trends ( data )","title":"plot_trends"},{"location":"dataframe_api/","text":"Anomeda DataFrame API Here you can find the documentation for anomeda.DataFrame class. DataFrame DataFrame ( * args , ** kwargs ) Bases: DataFrame Data to be processed by anomeda. The class inherits pandas.DataFrame. Please note that whenever the underlying pandas.DataFrame object is changed, you may need to apply the constructor again in order to keep some of the characteristics of the data consistent with the new object. Parameters: *args \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. **kwargs \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. measures_names ( 'list | tuple' = None ) \u2013 A list containing columns considered as measures. If None, your data is supposed to have no measures. measures_types ( 'dict' = None ) \u2013 A dictionary containing 'categorical' and/or 'continuous' keys and list of measures as values. Continuous measures will be discretized automatically if not presented in discretized_measures parameter. If your data has any measures, you must provide its' types. discretized_measures_mapping ( 'dict' = None ) \u2013 Custom dictionary with a mapping between a discrete value of the meauser and corresponding continous ranges. The lower bound must be including, the higher bound must be excluding. It uses the following format: { 'measure_name': { discrete_value_1: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [...]], descrete_value_2: ... } } discretized_measures ( 'dict' = None ) \u2013 A dictionary containig names of the measures as keys and array-like objects containing customly discretized values of the measure. If not provided, continuous measures will be discretized automatically. index_name ( 'str | list | None' = None ) \u2013 An index column containg Integer or pandas.DatetimeIndex. If None, index is taken from the pandas.DataFrame. metric_name ( str ) \u2013 A metric column. agg_func \u2013 Way of aggregating metric_name by measures. Can be 'sum', 'avg', 'count' or callable compatible with pandas.DataFrame.groupby. Examples: anmd_df = anomeda.DataFrame( df, measures_names=['dummy_measure_col', 'dummy_numeric_measure_col'], measures_types={ 'categorical': ['dummy_measure_col'], 'continuous': ['dummy_numeric_measure_col'] }, index_name='dt', metric_name='metric_col', agg_func='sum' ) copy_anomeda_df copy_anomeda_df () Return a copy of an anomeda.DataFrame object get_agg_func get_agg_func () Return the function used to aggregate the metric by measures. get_discretization_mapping get_discretization_mapping () Return a dict with a mapping between discrete values and actual ranges of continous measures. In some cases, there may be more than one interval for each discrete values Examples: >>> anmd_df.get_discretization_mapping() { 'dummy_numeric_measure': { 0: [[0.08506988648110014, 0.982366623262143]], # [[inc, exl)] 1: [[0.9855150328648835, 2.458970726947438]] # [[inc, exl)] } } get_discretized_measures get_discretized_measures () Return discretized versions of continous measures. get_index_name get_index_name () Return the name of an index column. get_measures_names get_measures_names () Return a list of columns considered as measures. get_measures_types get_measures_types () Return the measures_types dict. get_metric_name get_metric_name () Return the name of a metric column. replace_df replace_df ( data : pandas . DataFrame , inplace = False , keep_clusters : bool = False , keep_trends : bool = False , keep_discretization : bool = False , ) Replace the pandas.DataFrame content, underlying the anomeda.DataFrame, with a new one Parameters: data ( DataFrame ) \u2013 A new data object. inplace ( bool , default: False ) \u2013 If True, then no new object will be returned. Otherwise, create and return a new anomeda.DataFrame set_agg_func set_agg_func ( agg_func ) Set a function to aggregate the metric by measures. Parameters: agg_func \u2013 Can be \"sum\", \"avg\", \"count\" or callable compatible with pandas.DataFrame.groupby set_discretization_mapping set_discretization_mapping ( discretized_measures_mapping , recalculate_measures = True ) Set custom thresholds for discretization. Parameters: discretized_measures_mapping ( dict ) \u2013 Dict with mapping between discrete value of the meause and corresponding continous values. Threshold must have the following format. As you can see, several different ranges of continuous values may be mapped into the same descrete values if you want. The lower bound must be including, the higher bound must be excluding. { 'measure_name': { discrete_value: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [..., ...], ...], ... }, ... } Examples: anmd_df.set_discretization_mapping({ 'dummy_numeric_measure': { 0: [[0.00, 0.05001], [0.95, 1.001]], # may correspond to \"extreme\" values; 0.05 are 1. are excluding bounds 1: [[0.5, 0.94999]] # may correspond to \"normal\" values; 94999 is an excluding bound } }) set_discretized_measures set_discretized_measures ( discretized_measures : dict ) Set custom discretization for continous measures. Parameters: discretized_measures ( dict ) \u2013 Dict containing discrete values of each measure in the format {'measure_name': [0, 1, 1, ...]}. Array of values must have same shape as original measure had. set_measures_names set_measures_names ( measures_names ) Let anomeda.DataFrame object know what columns are measures. Columns are picked from an underlying pandas.DataFrame object, so they must be present there. Parameters: measures_names ( list of str ) \u2013 List containing columns which will be considered as measures set_measures_types set_measures_types ( measures_types : dict ) Set measures types. Measure can be either 'categorical' or 'continous'. Types are used to clusterize the data properly. Parameters: measures_types ( dict ) \u2013 Dict containing 'continous' and/or 'categorical' keys and lists of measures as values Examples: anmd_df.set_measures_types({ 'continous': ['numeric_measure_1'], 'categorical': ['measure_1'] }) set_metric_name set_metric_name ( metric_name ) Set the name of a metric to be analyzed. Parameters: metric_name ( str ) \u2013 Must be present among columns of an underlying pandas.DataFrame. If metric column is currently set as a measure, you need to change the list of measures first","title":"Anomeda DataFrame"},{"location":"dataframe_api/#anomeda-dataframe-api","text":"Here you can find the documentation for anomeda.DataFrame class.","title":"Anomeda DataFrame API"},{"location":"dataframe_api/#DataFrame.DataFrame","text":"DataFrame ( * args , ** kwargs ) Bases: DataFrame Data to be processed by anomeda. The class inherits pandas.DataFrame. Please note that whenever the underlying pandas.DataFrame object is changed, you may need to apply the constructor again in order to keep some of the characteristics of the data consistent with the new object. Parameters: *args \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. **kwargs \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. measures_names ( 'list | tuple' = None ) \u2013 A list containing columns considered as measures. If None, your data is supposed to have no measures. measures_types ( 'dict' = None ) \u2013 A dictionary containing 'categorical' and/or 'continuous' keys and list of measures as values. Continuous measures will be discretized automatically if not presented in discretized_measures parameter. If your data has any measures, you must provide its' types. discretized_measures_mapping ( 'dict' = None ) \u2013 Custom dictionary with a mapping between a discrete value of the meauser and corresponding continous ranges. The lower bound must be including, the higher bound must be excluding. It uses the following format: { 'measure_name': { discrete_value_1: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [...]], descrete_value_2: ... } } discretized_measures ( 'dict' = None ) \u2013 A dictionary containig names of the measures as keys and array-like objects containing customly discretized values of the measure. If not provided, continuous measures will be discretized automatically. index_name ( 'str | list | None' = None ) \u2013 An index column containg Integer or pandas.DatetimeIndex. If None, index is taken from the pandas.DataFrame. metric_name ( str ) \u2013 A metric column. agg_func \u2013 Way of aggregating metric_name by measures. Can be 'sum', 'avg', 'count' or callable compatible with pandas.DataFrame.groupby. Examples: anmd_df = anomeda.DataFrame( df, measures_names=['dummy_measure_col', 'dummy_numeric_measure_col'], measures_types={ 'categorical': ['dummy_measure_col'], 'continuous': ['dummy_numeric_measure_col'] }, index_name='dt', metric_name='metric_col', agg_func='sum' )","title":"DataFrame"},{"location":"dataframe_api/#DataFrame.DataFrame.copy_anomeda_df","text":"copy_anomeda_df () Return a copy of an anomeda.DataFrame object","title":"copy_anomeda_df"},{"location":"dataframe_api/#DataFrame.DataFrame.get_agg_func","text":"get_agg_func () Return the function used to aggregate the metric by measures.","title":"get_agg_func"},{"location":"dataframe_api/#DataFrame.DataFrame.get_discretization_mapping","text":"get_discretization_mapping () Return a dict with a mapping between discrete values and actual ranges of continous measures. In some cases, there may be more than one interval for each discrete values Examples: >>> anmd_df.get_discretization_mapping() { 'dummy_numeric_measure': { 0: [[0.08506988648110014, 0.982366623262143]], # [[inc, exl)] 1: [[0.9855150328648835, 2.458970726947438]] # [[inc, exl)] } }","title":"get_discretization_mapping"},{"location":"dataframe_api/#DataFrame.DataFrame.get_discretized_measures","text":"get_discretized_measures () Return discretized versions of continous measures.","title":"get_discretized_measures"},{"location":"dataframe_api/#DataFrame.DataFrame.get_index_name","text":"get_index_name () Return the name of an index column.","title":"get_index_name"},{"location":"dataframe_api/#DataFrame.DataFrame.get_measures_names","text":"get_measures_names () Return a list of columns considered as measures.","title":"get_measures_names"},{"location":"dataframe_api/#DataFrame.DataFrame.get_measures_types","text":"get_measures_types () Return the measures_types dict.","title":"get_measures_types"},{"location":"dataframe_api/#DataFrame.DataFrame.get_metric_name","text":"get_metric_name () Return the name of a metric column.","title":"get_metric_name"},{"location":"dataframe_api/#DataFrame.DataFrame.replace_df","text":"replace_df ( data : pandas . DataFrame , inplace = False , keep_clusters : bool = False , keep_trends : bool = False , keep_discretization : bool = False , ) Replace the pandas.DataFrame content, underlying the anomeda.DataFrame, with a new one Parameters: data ( DataFrame ) \u2013 A new data object. inplace ( bool , default: False ) \u2013 If True, then no new object will be returned. Otherwise, create and return a new anomeda.DataFrame","title":"replace_df"},{"location":"dataframe_api/#DataFrame.DataFrame.set_agg_func","text":"set_agg_func ( agg_func ) Set a function to aggregate the metric by measures. Parameters: agg_func \u2013 Can be \"sum\", \"avg\", \"count\" or callable compatible with pandas.DataFrame.groupby","title":"set_agg_func"},{"location":"dataframe_api/#DataFrame.DataFrame.set_discretization_mapping","text":"set_discretization_mapping ( discretized_measures_mapping , recalculate_measures = True ) Set custom thresholds for discretization. Parameters: discretized_measures_mapping ( dict ) \u2013 Dict with mapping between discrete value of the meause and corresponding continous values. Threshold must have the following format. As you can see, several different ranges of continuous values may be mapped into the same descrete values if you want. The lower bound must be including, the higher bound must be excluding. { 'measure_name': { discrete_value: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [..., ...], ...], ... }, ... } Examples: anmd_df.set_discretization_mapping({ 'dummy_numeric_measure': { 0: [[0.00, 0.05001], [0.95, 1.001]], # may correspond to \"extreme\" values; 0.05 are 1. are excluding bounds 1: [[0.5, 0.94999]] # may correspond to \"normal\" values; 94999 is an excluding bound } })","title":"set_discretization_mapping"},{"location":"dataframe_api/#DataFrame.DataFrame.set_discretized_measures","text":"set_discretized_measures ( discretized_measures : dict ) Set custom discretization for continous measures. Parameters: discretized_measures ( dict ) \u2013 Dict containing discrete values of each measure in the format {'measure_name': [0, 1, 1, ...]}. Array of values must have same shape as original measure had.","title":"set_discretized_measures"},{"location":"dataframe_api/#DataFrame.DataFrame.set_measures_names","text":"set_measures_names ( measures_names ) Let anomeda.DataFrame object know what columns are measures. Columns are picked from an underlying pandas.DataFrame object, so they must be present there. Parameters: measures_names ( list of str ) \u2013 List containing columns which will be considered as measures","title":"set_measures_names"},{"location":"dataframe_api/#DataFrame.DataFrame.set_measures_types","text":"set_measures_types ( measures_types : dict ) Set measures types. Measure can be either 'categorical' or 'continous'. Types are used to clusterize the data properly. Parameters: measures_types ( dict ) \u2013 Dict containing 'continous' and/or 'categorical' keys and lists of measures as values Examples: anmd_df.set_measures_types({ 'continous': ['numeric_measure_1'], 'categorical': ['measure_1'] })","title":"set_measures_types"},{"location":"dataframe_api/#DataFrame.DataFrame.set_metric_name","text":"set_metric_name ( metric_name ) Set the name of a metric to be analyzed. Parameters: metric_name ( str ) \u2013 Must be present among columns of an underlying pandas.DataFrame. If metric column is currently set as a measure, you need to change the list of measures first","title":"set_metric_name"},{"location":"usage_guide/","text":"Usage Guide What is anomeda.DataFrame anomeda.DataFrame is class used to store the time-series data and its metadata. It inherits pandas.DataFrame . One of the implications of that fact is that anomeda.DataFrame.__init__ processes the same parameters as its ancestor and a few more . Specifically: Parameters: *args \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. **kwargs \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. measures_names ( 'list | tuple' = None ) \u2013 A list containing columns considered as measures. If None, your data is supposed to have no measures. measures_types ( 'dict' = None ) \u2013 A dictionary containing 'categorical' and/or 'continuous' keys and list of measures as values. Continuous measures will be discretized automatically if not presented in discretized_measures parameter. If your data has any measures, you must provide its' types. discretized_measures_mapping ( 'dict' = None ) \u2013 Custom dictionary with a mapping between a discrete value of the meauser and corresponding continous ranges. The lower bound must be including, the higher bound must be excluding. It uses the following format: { 'measure_name': { discrete_value_1: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [...]], descrete_value_2: ... } } discretized_measures ( 'dict' = None ) \u2013 A dictionary containig names of the measures as keys and array-like objects containing customly discretized values of the measure. If not provided, continuous measures will be discretized automatically. index_name ( 'str | list | None' = None ) \u2013 An index column containg Integer or pandas.DatetimeIndex. If None, index is taken from the pandas.DataFrame. metric_name ( str ) \u2013 A metric column. agg_func \u2013 Way of aggregating metric_name by measures. Can be 'sum', 'avg', 'count' or callable compatible with pandas.DataFrame.groupby. As you may have noticed, most of the parameters are optional. If you don't specify a parameter, a default value will be used. Or you will be notified once you use anomeda.fit_trends , anomeda.find_anomalies or other methods that you need to specify something additionally. Note that it is recommended to use datetime-like index or integer index . You can map change the type of your index to datetime, for example, using pandas.to_datetime . Anomeda will try to change the type automatically, but it may cause unexpected results. If it failes, it will try to convert index values to int64 . Here is some examples of how you can initialize a new anomeda.DataFrame : # With just a pandas.DataFrame and metric name anomeda.DataFrame(pandas_df, metric_name='my_metric') # With some measures anomeda.DataFrame(pandas_df, measures_names=['A', 'B', 'C'], metric_name='my_metric') # In a pandas.DataFrame style anomeda.DataFrame( { 'A': [0, 1, 2], 'B': [3, 4, 5], 'C': [6, 7, 8], 'my_metric': [10, 20, 30] } measures_names=['A', 'B', 'C'], metric_name='my_metric' ) # With a discretization mappging anomeda.DataFrame( pandas_df, measures_names=['A', 'B', 'C'], metric_name='my_metric', discretized_measures_mapping={ 'A': { 0: [[20, 80]], # map values from 20 to 80 to 0 - \"normal values\" 1: [[0, 20], [80, 100]], # map values from 0 and 20 or between 80 and 100 to 1 - \"abnormal values\" } } ) # And many more... NOTE 1 Some pandas methods are not yet adapted for anomeda . They return a new pandas.DataFrame instead of a anomeda.DataFrame . You just need to initialize an anomeda object with a returned object in that case. NOTE 2 The scale of undex increments is extracted automatically. It can be 1 ( Integer , if your index are integers) or a part of a timestamp ( second , minute , hour , etc). For example, if your index consists of two values ['2024-01-01 00:00:00', '2024-01-01 00:01:00'], the step is hour . However, the step may become minute once you add only one value - ['2024-01-01 00:00:00', '2024-01-01 00:01:00', '2024-01-01 00:01: 01 '], since minute is the smallest increment now. By default, anomeda does not propagate metric values for the missing index values in clusters. However, you can specify a different option by providing metric_propagate parameters to anomeda.fit_trends . It can be \"zeros\" (fill missing metric values with zeros), \"ffil\" (use the last present metric value) or None (do not fill any missing values, treat them as it is). A list of methods available to manipulate anomeda.DataFrame , such as getters , setters , copying , modifying the object , etc. Please follow anomeda.DataFrame API Reference for the details. Her is the full list: copy_anomeda_df get_agg_func get_discretization_mapping get_discretized_measures get_index_name get_measures_names get_measures_types get_metric_name replace_df set_agg_func set_discretization_mapping set_discretized_measures set_measures_names set_measures_types set_metric_name How we handle continuous measures Measures with continuous values are mapped to discrete ones by sklearn.mixture.BayesianGaussianMixture by default. It helps to divide the data into interpretable clusters. Usually the mapped values represent more or less isolated ranges where the feature is concentrated, like \"tiny\", \"medium\", \"large\" or other categories. The anomeda._to_discrete_values is responsible for the transformation, you may redefine it if needed. You can pass specific discrete values of a continuous measure both when creating an anomeda.DataFrame object and later. See discretized_measures parameter of anomeda.DataFrame.__init__ or anomeda.DataFrame.set_discretized_measures . Alternatively, you may pass a mapping describing how to transform your continuous values into discrete ones, see the discretized_measures_mapping parameter of anomeda.DataFrame.__init__ or anomeda.DataFrame.set_discretization_mapping . You can then access the mapping and the discretized values by anomeda.DataFrame.get_discretization_mapping and anomeda.DataFrame.get_discretized_measures respectively. How we fit trends Anomeda can fit trends of a time-series. Why trends, but not a trend? Becuase it can automatically identify when a trend changes and return not one, but actual number of trend. All the work is made by anomeda.fit_trends method. It can fit trends, plot them and assign it to the anomeda.DataFrame._trends attribute for reusing. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) | ( DatetimeIndex , ndarray [ float ]) ) \u2013 Object containing metric values. If numpy.ndarray, a tuple of arrays corresponding to x (data points) and y (metric values) respectively. trend_fitting_conf ( dict , default: {'max_trends': 'auto', 'min_var_reduction': 0.75} ) \u2013 Parameters for calling anomeda.extract_trends() function. It consists of 'max_trends' parameter, which is responsible for the maximum number of trends that you want to identify, and 'min_var_reduction' parameter, which describes what part of variance must be reduced by estimating trends. Values close to 1 will produce more trends since more trends reduce variance more signigicantly. Default is {'max_trends': 'auto', 'min_var_reduction': 0.75}. save_trends ( bool , default: True ) \u2013 If False, return pandas.DataFrame with trends description without assigning it to the anomeda.DataFrame._trends. breakdown ( no | all - clusters | list [ str ] , default: 'no' ) \u2013 If 'no', the metric is grouped by date points only. If 'all-clusters', then all combinations of measures are used to create clusters for fitting trends within them. If list[str], then only combinations of measures specified in the list are used. metric_propagate ( '\"zeros\" | \"ffil\" | None' = None , default: None ) \u2013 How to propogate aggregated time-series for missing index values. - zeros: Let metric for missing index be equal 0. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 0 '2024-01-03': 2 - ffil: Let metric for missing index be equal the last observed value. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 1 '2024-01-03': 2 - None: Use only present metric and index values. min_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is less than the value. max_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is more than the value. plot ( bool , default: False ) \u2013 Indicator if to plot fitted trends. anomeda.plot_trends is responsibe for plotting if the flag is True. df ( bool , default: True ) \u2013 Indicator if to return a pandas.DataFrame containing fitted trends. verbose ( bool , default: False ) \u2013 Indicator if to print additional output. Returns: resp ( DataFrame ) \u2013 An object containing information about trends Examples: >>> fitted_trends = anomeda . fit_trends ( data, trend_fitting_conf={'max_trends': 3}, metric_propagate='zeros', min_cluster_size=3, plot=True, df=True ) The underlying algorithm starts with one trend. It estimates the parameters of a linear function. by optimizing. After one trend is fitted, the algorithm tries to find a point which will reduce the an interesting metric, variance of an absolute error (VAE) multiplied by 90-th percentile of an absolute error , if we \"break\" the trend there and reestimate trends for the left and the right part of a time-series. The left and right trends which reduce the VAE the most are now our current trends. If we already fitted enough trends, defined by max_n_trends , or the current VAE is at least by min_var_reduction lower from what we saw using one trend, the algorithm stops and returns the trends. Otherwise, it starts to \"break\" each trend into two pieces the same way as described. When a breaking point is being searched, either all points with presented data or a randomly sampled points are used as candidates. What is important, a kind of a regularization is used during the search. Choosing a point located closer to the ends of an index range is penalized more than closer to the center. We use PDF of Beta-function as a multiplicator. It was made to balance the number of samples in the left and right parts of the range. The low number of samples in one of the parts may cause a lower error variance there, which will hinder extracting long and consistent trends. The method returns all the trends and the breaking points: If you plot one of them with anomeda.plot_trends , you may see what the result looks like: While fitting trends, the method also stores clusters to anomeda.DataFrame._clusters . If you want to query them in other methods, remember that you must query them exactly how they are called in this property (only measures may have a different order). The syntax is the following: \"`measure_name_1`==measure_value_1 and `measure_name_1`==measure_value_1 and ...\". Also, note that discretized values of continous measures are used as measure values in clusters definitions. How we detect anomalies The algorithm of detecting anomalies is based on comparing observed values with values of a fitted trend. Sounds simple, doesn't it?. The interesting part is how the anomalies are identified based on its differences from a trend. Once differences between observed values and fitted trend are calculated, we apply the Local Outlier Factor algorithm with a provided n_neighbors . It identifies \"isolated\" (without many neighbors) points or clusters and mark them as outliers. So, we find differences which are too rare, i.e. little or no points have similar difference. Such an alghorithm let us handle data with a high variance where lot's of differences are far from the trend, as well as not to mark points as anomalies if there are none of them. Once we identified abnormal clusters, we filter points with only the lowest and the highest differences, meaning for each low-value anomaly there must be no normal points with a difference lower than given, and similarly for the high-value anomalies - no points must have a difference higher than given. Finally, the amount of points to return is customized with p_large and p_low parameters which set the fraction of the most extreme points to return. The parameters vary from 0 to 1. Anomalies are identified with anomeda.find_anomalies method. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) ) \u2013 Object containing metric values to be analyzed. Trends must be fitted for the object with anomeda.fit_trends() method if anomeda.DataFrame is passed. clusters ( list , default: None ) \u2013 List of clusters to plot. The objects in the list are queries used in pandas.DataFrame.query. Make sure you pass the cluster names exactly as they they appear in the fitted trends. anomalies_conf ( dict , default: {'p_large': 1., 'p_low': 1., 'n_neighbors': 3} ) \u2013 Dict containing 'p_large' and 'p_low' values. Both are float values between 0 and 1 corresponding to the % of the anomalies with largest and lowest metric values to be returned. For example, if you set 'p_low' to 0, no points with abnormally low metric values will be returned; if 0.5, then 50% of points with abnormally values will be returned, etc. If some of the keys is not present or None, 1 is assumed. 'n_neighbors' means number of neighbors parameter for sklearn.neighbors.LocalOutlierFactor class. The class is used to find points with abnormally large MAE. The more the parameter, typically, the less sensitive the model to anomalies. return_all_points ( bool , default: False ) \u2013 If False, only anomaly points are returned. If True, all points with anomalies marks are returned. Default False. trend_fitting_conf ( dict , default: None ) \u2013 Used only if data is not anomeda.DataFrame, but numpy arrays, to run anomeda.fit_trends method for them. Parameters are similar to those you would pass to the argument anomeda.fit_trends(..., trend_fitting_conf=...). Returns: res ( DataFrame ) \u2013 A DataFrame containing fields 'cluster', 'index', 'metric_value', 'fitted_trend_value', 'anomaly'. Examples: >>> anomeda . fit_trends ( data ) >>> anomeda . find_anomalies ( data )","title":"Usage Guide"},{"location":"usage_guide/#usage-guide","text":"","title":"Usage Guide"},{"location":"usage_guide/#what-is-anomedadataframe","text":"anomeda.DataFrame is class used to store the time-series data and its metadata. It inherits pandas.DataFrame . One of the implications of that fact is that anomeda.DataFrame.__init__ processes the same parameters as its ancestor and a few more . Specifically: Parameters: *args \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. **kwargs \u2013 Parameters for initialization a pandas.DataFrame object. Other parameters must be passed as **kwargs only. measures_names ( 'list | tuple' = None ) \u2013 A list containing columns considered as measures. If None, your data is supposed to have no measures. measures_types ( 'dict' = None ) \u2013 A dictionary containing 'categorical' and/or 'continuous' keys and list of measures as values. Continuous measures will be discretized automatically if not presented in discretized_measures parameter. If your data has any measures, you must provide its' types. discretized_measures_mapping ( 'dict' = None ) \u2013 Custom dictionary with a mapping between a discrete value of the meauser and corresponding continous ranges. The lower bound must be including, the higher bound must be excluding. It uses the following format: { 'measure_name': { discrete_value_1: [[continuous_threshold_min_inc, continuous_threshold_max_excl], [...]], descrete_value_2: ... } } discretized_measures ( 'dict' = None ) \u2013 A dictionary containig names of the measures as keys and array-like objects containing customly discretized values of the measure. If not provided, continuous measures will be discretized automatically. index_name ( 'str | list | None' = None ) \u2013 An index column containg Integer or pandas.DatetimeIndex. If None, index is taken from the pandas.DataFrame. metric_name ( str ) \u2013 A metric column. agg_func \u2013 Way of aggregating metric_name by measures. Can be 'sum', 'avg', 'count' or callable compatible with pandas.DataFrame.groupby. As you may have noticed, most of the parameters are optional. If you don't specify a parameter, a default value will be used. Or you will be notified once you use anomeda.fit_trends , anomeda.find_anomalies or other methods that you need to specify something additionally. Note that it is recommended to use datetime-like index or integer index . You can map change the type of your index to datetime, for example, using pandas.to_datetime . Anomeda will try to change the type automatically, but it may cause unexpected results. If it failes, it will try to convert index values to int64 . Here is some examples of how you can initialize a new anomeda.DataFrame : # With just a pandas.DataFrame and metric name anomeda.DataFrame(pandas_df, metric_name='my_metric') # With some measures anomeda.DataFrame(pandas_df, measures_names=['A', 'B', 'C'], metric_name='my_metric') # In a pandas.DataFrame style anomeda.DataFrame( { 'A': [0, 1, 2], 'B': [3, 4, 5], 'C': [6, 7, 8], 'my_metric': [10, 20, 30] } measures_names=['A', 'B', 'C'], metric_name='my_metric' ) # With a discretization mappging anomeda.DataFrame( pandas_df, measures_names=['A', 'B', 'C'], metric_name='my_metric', discretized_measures_mapping={ 'A': { 0: [[20, 80]], # map values from 20 to 80 to 0 - \"normal values\" 1: [[0, 20], [80, 100]], # map values from 0 and 20 or between 80 and 100 to 1 - \"abnormal values\" } } ) # And many more... NOTE 1 Some pandas methods are not yet adapted for anomeda . They return a new pandas.DataFrame instead of a anomeda.DataFrame . You just need to initialize an anomeda object with a returned object in that case. NOTE 2 The scale of undex increments is extracted automatically. It can be 1 ( Integer , if your index are integers) or a part of a timestamp ( second , minute , hour , etc). For example, if your index consists of two values ['2024-01-01 00:00:00', '2024-01-01 00:01:00'], the step is hour . However, the step may become minute once you add only one value - ['2024-01-01 00:00:00', '2024-01-01 00:01:00', '2024-01-01 00:01: 01 '], since minute is the smallest increment now. By default, anomeda does not propagate metric values for the missing index values in clusters. However, you can specify a different option by providing metric_propagate parameters to anomeda.fit_trends . It can be \"zeros\" (fill missing metric values with zeros), \"ffil\" (use the last present metric value) or None (do not fill any missing values, treat them as it is). A list of methods available to manipulate anomeda.DataFrame , such as getters , setters , copying , modifying the object , etc. Please follow anomeda.DataFrame API Reference for the details. Her is the full list:","title":"What is anomeda.DataFrame"},{"location":"usage_guide/#DataFrame.DataFrame.copy_anomeda_df","text":"","title":"copy_anomeda_df"},{"location":"usage_guide/#DataFrame.DataFrame.get_agg_func","text":"","title":"get_agg_func"},{"location":"usage_guide/#DataFrame.DataFrame.get_discretization_mapping","text":"","title":"get_discretization_mapping"},{"location":"usage_guide/#DataFrame.DataFrame.get_discretized_measures","text":"","title":"get_discretized_measures"},{"location":"usage_guide/#DataFrame.DataFrame.get_index_name","text":"","title":"get_index_name"},{"location":"usage_guide/#DataFrame.DataFrame.get_measures_names","text":"","title":"get_measures_names"},{"location":"usage_guide/#DataFrame.DataFrame.get_measures_types","text":"","title":"get_measures_types"},{"location":"usage_guide/#DataFrame.DataFrame.get_metric_name","text":"","title":"get_metric_name"},{"location":"usage_guide/#DataFrame.DataFrame.replace_df","text":"","title":"replace_df"},{"location":"usage_guide/#DataFrame.DataFrame.set_agg_func","text":"","title":"set_agg_func"},{"location":"usage_guide/#DataFrame.DataFrame.set_discretization_mapping","text":"","title":"set_discretization_mapping"},{"location":"usage_guide/#DataFrame.DataFrame.set_discretized_measures","text":"","title":"set_discretized_measures"},{"location":"usage_guide/#DataFrame.DataFrame.set_measures_names","text":"","title":"set_measures_names"},{"location":"usage_guide/#DataFrame.DataFrame.set_measures_types","text":"","title":"set_measures_types"},{"location":"usage_guide/#DataFrame.DataFrame.set_metric_name","text":"","title":"set_metric_name"},{"location":"usage_guide/#how-we-handle-continuous-measures","text":"Measures with continuous values are mapped to discrete ones by sklearn.mixture.BayesianGaussianMixture by default. It helps to divide the data into interpretable clusters. Usually the mapped values represent more or less isolated ranges where the feature is concentrated, like \"tiny\", \"medium\", \"large\" or other categories. The anomeda._to_discrete_values is responsible for the transformation, you may redefine it if needed. You can pass specific discrete values of a continuous measure both when creating an anomeda.DataFrame object and later. See discretized_measures parameter of anomeda.DataFrame.__init__ or anomeda.DataFrame.set_discretized_measures . Alternatively, you may pass a mapping describing how to transform your continuous values into discrete ones, see the discretized_measures_mapping parameter of anomeda.DataFrame.__init__ or anomeda.DataFrame.set_discretization_mapping . You can then access the mapping and the discretized values by anomeda.DataFrame.get_discretization_mapping and anomeda.DataFrame.get_discretized_measures respectively.","title":"How we handle continuous measures"},{"location":"usage_guide/#how-we-fit-trends","text":"Anomeda can fit trends of a time-series. Why trends, but not a trend? Becuase it can automatically identify when a trend changes and return not one, but actual number of trend. All the work is made by anomeda.fit_trends method. It can fit trends, plot them and assign it to the anomeda.DataFrame._trends attribute for reusing. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) | ( DatetimeIndex , ndarray [ float ]) ) \u2013 Object containing metric values. If numpy.ndarray, a tuple of arrays corresponding to x (data points) and y (metric values) respectively. trend_fitting_conf ( dict , default: {'max_trends': 'auto', 'min_var_reduction': 0.75} ) \u2013 Parameters for calling anomeda.extract_trends() function. It consists of 'max_trends' parameter, which is responsible for the maximum number of trends that you want to identify, and 'min_var_reduction' parameter, which describes what part of variance must be reduced by estimating trends. Values close to 1 will produce more trends since more trends reduce variance more signigicantly. Default is {'max_trends': 'auto', 'min_var_reduction': 0.75}. save_trends ( bool , default: True ) \u2013 If False, return pandas.DataFrame with trends description without assigning it to the anomeda.DataFrame._trends. breakdown ( no | all - clusters | list [ str ] , default: 'no' ) \u2013 If 'no', the metric is grouped by date points only. If 'all-clusters', then all combinations of measures are used to create clusters for fitting trends within them. If list[str], then only combinations of measures specified in the list are used. metric_propagate ( '\"zeros\" | \"ffil\" | None' = None , default: None ) \u2013 How to propogate aggregated time-series for missing index values. - zeros: Let metric for missing index be equal 0. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 0 '2024-01-03': 2 - ffil: Let metric for missing index be equal the last observed value. For example, aggregated metric values '2024-01-01': 1 '2024-01-03': 2 Will be propagated as '2024-01-01': 1 '2024-01-02': 1 '2024-01-03': 2 - None: Use only present metric and index values. min_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is less than the value. max_cluster_size ( int , default: None ) \u2013 Skip clusters whose total size among all date points is more than the value. plot ( bool , default: False ) \u2013 Indicator if to plot fitted trends. anomeda.plot_trends is responsibe for plotting if the flag is True. df ( bool , default: True ) \u2013 Indicator if to return a pandas.DataFrame containing fitted trends. verbose ( bool , default: False ) \u2013 Indicator if to print additional output. Returns: resp ( DataFrame ) \u2013 An object containing information about trends Examples: >>> fitted_trends = anomeda . fit_trends ( data, trend_fitting_conf={'max_trends': 3}, metric_propagate='zeros', min_cluster_size=3, plot=True, df=True ) The underlying algorithm starts with one trend. It estimates the parameters of a linear function. by optimizing. After one trend is fitted, the algorithm tries to find a point which will reduce the an interesting metric, variance of an absolute error (VAE) multiplied by 90-th percentile of an absolute error , if we \"break\" the trend there and reestimate trends for the left and the right part of a time-series. The left and right trends which reduce the VAE the most are now our current trends. If we already fitted enough trends, defined by max_n_trends , or the current VAE is at least by min_var_reduction lower from what we saw using one trend, the algorithm stops and returns the trends. Otherwise, it starts to \"break\" each trend into two pieces the same way as described. When a breaking point is being searched, either all points with presented data or a randomly sampled points are used as candidates. What is important, a kind of a regularization is used during the search. Choosing a point located closer to the ends of an index range is penalized more than closer to the center. We use PDF of Beta-function as a multiplicator. It was made to balance the number of samples in the left and right parts of the range. The low number of samples in one of the parts may cause a lower error variance there, which will hinder extracting long and consistent trends. The method returns all the trends and the breaking points: If you plot one of them with anomeda.plot_trends , you may see what the result looks like: While fitting trends, the method also stores clusters to anomeda.DataFrame._clusters . If you want to query them in other methods, remember that you must query them exactly how they are called in this property (only measures may have a different order). The syntax is the following: \"`measure_name_1`==measure_value_1 and `measure_name_1`==measure_value_1 and ...\". Also, note that discretized values of continous measures are used as measure values in clusters definitions.","title":"How we fit trends"},{"location":"usage_guide/#how-we-detect-anomalies","text":"The algorithm of detecting anomalies is based on comparing observed values with values of a fitted trend. Sounds simple, doesn't it?. The interesting part is how the anomalies are identified based on its differences from a trend. Once differences between observed values and fitted trend are calculated, we apply the Local Outlier Factor algorithm with a provided n_neighbors . It identifies \"isolated\" (without many neighbors) points or clusters and mark them as outliers. So, we find differences which are too rare, i.e. little or no points have similar difference. Such an alghorithm let us handle data with a high variance where lot's of differences are far from the trend, as well as not to mark points as anomalies if there are none of them. Once we identified abnormal clusters, we filter points with only the lowest and the highest differences, meaning for each low-value anomaly there must be no normal points with a difference lower than given, and similarly for the high-value anomalies - no points must have a difference higher than given. Finally, the amount of points to return is customized with p_large and p_low parameters which set the fraction of the most extreme points to return. The parameters vary from 0 to 1. Anomalies are identified with anomeda.find_anomalies method. Parameters: data ( DataFrame | ( ndarray [ int ], ndarray [ float ]) ) \u2013 Object containing metric values to be analyzed. Trends must be fitted for the object with anomeda.fit_trends() method if anomeda.DataFrame is passed. clusters ( list , default: None ) \u2013 List of clusters to plot. The objects in the list are queries used in pandas.DataFrame.query. Make sure you pass the cluster names exactly as they they appear in the fitted trends. anomalies_conf ( dict , default: {'p_large': 1., 'p_low': 1., 'n_neighbors': 3} ) \u2013 Dict containing 'p_large' and 'p_low' values. Both are float values between 0 and 1 corresponding to the % of the anomalies with largest and lowest metric values to be returned. For example, if you set 'p_low' to 0, no points with abnormally low metric values will be returned; if 0.5, then 50% of points with abnormally values will be returned, etc. If some of the keys is not present or None, 1 is assumed. 'n_neighbors' means number of neighbors parameter for sklearn.neighbors.LocalOutlierFactor class. The class is used to find points with abnormally large MAE. The more the parameter, typically, the less sensitive the model to anomalies. return_all_points ( bool , default: False ) \u2013 If False, only anomaly points are returned. If True, all points with anomalies marks are returned. Default False. trend_fitting_conf ( dict , default: None ) \u2013 Used only if data is not anomeda.DataFrame, but numpy arrays, to run anomeda.fit_trends method for them. Parameters are similar to those you would pass to the argument anomeda.fit_trends(..., trend_fitting_conf=...). Returns: res ( DataFrame ) \u2013 A DataFrame containing fields 'cluster', 'index', 'metric_value', 'fitted_trend_value', 'anomaly'. Examples: >>> anomeda . fit_trends ( data ) >>> anomeda . find_anomalies ( data )","title":"How we detect anomalies"}]}